{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTR1lx42JP5_",
        "outputId": "9ef01666-51fc-442e-a52f-044a283f5549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-11 04:34:40--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.32.241, 104.16.191.158, 2606:4700::6810:bf9e, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.32.241|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 155472915 (148M) [application/octet-stream]\n",
            "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-latest-L 100%[===================>] 148.27M   289MB/s    in 0.5s    \n",
            "\n",
            "2025-05-11 04:34:40 (289 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [155472915/155472915]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "entry_point.py:256: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "entry_point.py:256: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "\n",
            "Installing base environment...\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "entry_point.py:256: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Channels:\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/py38\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.8\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    pip-24.2                   |   py38h06a4308_0         2.2 MB\n",
            "    python-3.8.20              |       he870216_0        23.8 MB\n",
            "    setuptools-75.1.0          |   py38h06a4308_0         1.7 MB\n",
            "    wheel-0.44.0               |   py38h06a4308_0         108 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        27.8 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2025.2.25-h06a4308_0 \n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.40-h12ee557_0 \n",
            "  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 \n",
            "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 \n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 \n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0 \n",
            "  openssl            pkgs/main/linux-64::openssl-3.0.16-h5eee18b_0 \n",
            "  pip                pkgs/main/linux-64::pip-24.2-py38h06a4308_0 \n",
            "  python             pkgs/main/linux-64::python-3.8.20-he870216_0 \n",
            "  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0 \n",
            "  setuptools         pkgs/main/linux-64::setuptools-75.1.0-py38h06a4308_0 \n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.45.3-h5eee18b_0 \n",
            "  tk                 pkgs/main/linux-64::tk-8.6.14-h39e8969_0 \n",
            "  wheel              pkgs/main/linux-64::wheel-0.44.0-py38h06a4308_0 \n",
            "  xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 \n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_1 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "python-3.8.20        | 23.8 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "pip-24.2             | 2.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "setuptools-75.1.0    | 1.7 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "wheel-0.44.0         | 108 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "wheel-0.44.0         | 108 KB    | : 100% 1.0/1 [00:00<00:00, 26.21it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "python-3.8.20        | 23.8 MB   | :  21% 0.21424746715550255/1 [00:00<00:00,  2.14it/s]\n",
            "pip-24.2             | 2.2 MB    | : 100% 1.0/1 [00:00<00:00,  9.95it/s]\u001b[A\n",
            "pip-24.2             | 2.2 MB    | : 100% 1.0/1 [00:00<00:00,  9.95it/s]\u001b[A\n",
            "\n",
            "\n",
            "wheel-0.44.0         | 108 KB    | : 100% 1.0/1 [00:00<00:00,  8.18it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "python-3.8.20        | 23.8 MB   | : 100% 1.0/1 [00:00<00:00,  1.81it/s]\n",
            "pip-24.2             | 2.2 MB    | : 100% 1.0/1 [00:00<00:00,  9.95it/s]\u001b[A\n",
            "\n",
            "setuptools-75.1.0    | 1.7 MB    | : 100% 1.0/1 [00:00<00:00,  1.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: / \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate py38\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "Python 3.8.20\n",
            "Channels:\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\bdone\n",
            "\n",
            "# All requested packages already installed.\n",
            "\n",
            "Collecting torch==2.0.1\n",
            "  Downloading torch-2.0.1-cp38-cp38-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting transformers==4.36.2\n",
            "  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
            "Collecting numpy==1.24.4\n",
            "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting filelock (from torch==2.0.1)\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions (from torch==2.0.1)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy (from torch==2.0.1)\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch==2.0.1)\n",
            "  Downloading networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting jinja2 (from torch==2.0.1)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers==4.36.2)\n",
            "  Downloading huggingface_hub-0.31.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting packaging>=20.0 (from transformers==4.36.2)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pyyaml>=5.1 (from transformers==4.36.2)\n",
            "  Downloading PyYAML-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers==4.36.2)\n",
            "  Downloading regex-2024.11.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting requests (from transformers==4.36.2)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.36.2)\n",
            "  Downloading tokenizers-0.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting safetensors>=0.3.1 (from transformers==4.36.2)\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting tqdm>=4.27 (from transformers==4.36.2)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/envs/py38/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/envs/py38/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.44.0)\n",
            "Collecting cmake (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading cmake-4.0.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.0 (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2)\n",
            "  Downloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (494 bytes)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.0.1)\n",
            "  Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->transformers==4.36.2)\n",
            "  Downloading charset_normalizer-3.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->transformers==4.36.2)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers==4.36.2)\n",
            "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers==4.36.2)\n",
            "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.0.1)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading torch-2.0.1-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m142.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m187.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m166.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m180.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m142.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m150.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m147.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m141.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "Downloading triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.2/63.2 MB\u001b[0m \u001b[31m113.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.31.1-py3-none-any.whl (484 kB)\n",
            "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading PyYAML-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (746 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m746.5/746.5 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2024.11.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.1/785.1 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "Downloading tokenizers-0.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m157.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
            "Downloading charset_normalizer-3.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (147 kB)\n",
            "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Downloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 MB\u001b[0m \u001b[31m155.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "Downloading cmake-4.0.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m188.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "Installing collected packages: mpmath, lit, urllib3, typing-extensions, tqdm, sympy, safetensors, regex, pyyaml, packaging, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, MarkupSafe, idna, hf-xet, fsspec, filelock, cmake, charset-normalizer, certifi, requests, nvidia-cusolver-cu11, nvidia-cudnn-cu11, jinja2, huggingface-hub, tokenizers, transformers, triton, torch\n",
            "Successfully installed MarkupSafe-2.1.5 certifi-2025.4.26 charset-normalizer-3.4.2 cmake-4.0.2 filelock-3.16.1 fsspec-2025.3.0 hf-xet-1.1.0 huggingface-hub-0.31.1 idna-3.10 jinja2-3.1.6 lit-18.1.8 mpmath-1.3.0 networkx-3.1 numpy-1.24.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 packaging-25.0 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.3 sympy-1.13.3 tokenizers-0.15.2 torch-2.0.1 tqdm-4.67.1 transformers-4.36.2 triton-2.0.0 typing-extensions-4.13.2 urllib3-2.2.3\n",
            "Cloning into 'DeepSeek-VL'...\n",
            "remote: Enumerating objects: 119, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 119 (delta 31), reused 15 (delta 15), pack-reused 66 (from 1)\u001b[K\n",
            "Receiving objects: 100% (119/119), 12.47 MiB | 13.62 MiB/s, done.\n",
            "Resolving deltas: 100% (40/40), done.\n",
            "Obtaining file:///content/DeepSeek-VL\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.0.1 in /usr/local/envs/py38/lib/python3.8/site-packages (from deepseek_vl==1.0.0) (2.0.1)\n",
            "Collecting transformers>=4.38.2 (from deepseek_vl==1.0.0)\n",
            "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
            "Collecting timm>=0.9.16 (from deepseek_vl==1.0.0)\n",
            "  Downloading timm-1.0.15-py3-none-any.whl.metadata (52 kB)\n",
            "Collecting accelerate (from deepseek_vl==1.0.0)\n",
            "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting sentencepiece (from deepseek_vl==1.0.0)\n",
            "  Downloading sentencepiece-0.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting attrdict (from deepseek_vl==1.0.0)\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting einops (from deepseek_vl==1.0.0)\n",
            "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting torchvision (from timm>=0.9.16->deepseek_vl==1.0.0)\n",
            "  Downloading torchvision-0.19.1-cp38-cp38-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/envs/py38/lib/python3.8/site-packages (from timm>=0.9.16->deepseek_vl==1.0.0) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/envs/py38/lib/python3.8/site-packages (from timm>=0.9.16->deepseek_vl==1.0.0) (0.31.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/envs/py38/lib/python3.8/site-packages (from timm>=0.9.16->deepseek_vl==1.0.0) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/envs/py38/lib/python3.8/site-packages (from torch>=2.0.1->deepseek_vl==1.0.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/envs/py38/lib/python3.8/site-packages (from torch>=2.0.1->deepseek_vl==1.0.0) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/envs/py38/lib/python3.8/site-packages (from torch>=2.0.1->deepseek_vl==1.0.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/envs/py38/lib/python3.8/site-packages (from torch>=2.0.1->deepseek_vl==1.0.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/envs/py38/lib/python3.8/site-packages (from torch>=2.0.1->deepseek_vl==1.0.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/envs/py38/lib/python3.8/site-packages (from torch>=2.0.1->deepseek_vl==1.0.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/envs/py38/lib/python3.8/site-packages (from torch>=2.0.1->deepseek_vl==1.0.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/envs/py38/lib/python3.8/site-packages (from torch>=2.0.1->deepseek_vl==1.0.0) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/envs/py38/lib/python3.8/site-packages (from torch>=2.0.1->deepseek_vl==1.0.0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/envs/py38/lib/python3.8/site-packages (from torch>=2.0.1->deepseek_vl==1.0.0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/envs/py38/lib/python3.8/site-packages (from torch>=2.0.1->deepseek_vl==1.0.0) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/envs/py38/lib/python3.8/site-packages (from torch>=2.0.1->deepseek_vl==1.0.0) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/envs/py38/lib/python3.8/site-packages (from torch>=2.0.1->deepseek_vl==1.0.0) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/envs/py38/lib/python3.8/site-packages (from torch>=2.0.1->deepseek_vl==1.0.0) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/envs/py38/lib/python3.8/site-packages (from torch>=2.0.1->deepseek_vl==1.0.0) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/envs/py38/lib/python3.8/site-packages (from torch>=2.0.1->deepseek_vl==1.0.0) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/envs/py38/lib/python3.8/site-packages (from torch>=2.0.1->deepseek_vl==1.0.0) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/envs/py38/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=2.0.1->deepseek_vl==1.0.0) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/envs/py38/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=2.0.1->deepseek_vl==1.0.0) (0.44.0)\n",
            "Requirement already satisfied: cmake in /usr/local/envs/py38/lib/python3.8/site-packages (from triton==2.0.0->torch>=2.0.1->deepseek_vl==1.0.0) (4.0.2)\n",
            "Requirement already satisfied: lit in /usr/local/envs/py38/lib/python3.8/site-packages (from triton==2.0.0->torch>=2.0.1->deepseek_vl==1.0.0) (18.1.8)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/envs/py38/lib/python3.8/site-packages (from transformers>=4.38.2->deepseek_vl==1.0.0) (1.24.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/envs/py38/lib/python3.8/site-packages (from transformers>=4.38.2->deepseek_vl==1.0.0) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/envs/py38/lib/python3.8/site-packages (from transformers>=4.38.2->deepseek_vl==1.0.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/envs/py38/lib/python3.8/site-packages (from transformers>=4.38.2->deepseek_vl==1.0.0) (2.32.3)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers>=4.38.2->deepseek_vl==1.0.0)\n",
            "  Downloading tokenizers-0.20.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/envs/py38/lib/python3.8/site-packages (from transformers>=4.38.2->deepseek_vl==1.0.0) (4.67.1)\n",
            "Collecting psutil (from accelerate->deepseek_vl==1.0.0)\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting six (from attrdict->deepseek_vl==1.0.0)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/envs/py38/lib/python3.8/site-packages (from huggingface_hub->timm>=0.9.16->deepseek_vl==1.0.0) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/envs/py38/lib/python3.8/site-packages (from huggingface_hub->timm>=0.9.16->deepseek_vl==1.0.0) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/envs/py38/lib/python3.8/site-packages (from jinja2->torch>=2.0.1->deepseek_vl==1.0.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/envs/py38/lib/python3.8/site-packages (from requests->transformers>=4.38.2->deepseek_vl==1.0.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/envs/py38/lib/python3.8/site-packages (from requests->transformers>=4.38.2->deepseek_vl==1.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/envs/py38/lib/python3.8/site-packages (from requests->transformers>=4.38.2->deepseek_vl==1.0.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/py38/lib/python3.8/site-packages (from requests->transformers>=4.38.2->deepseek_vl==1.0.0) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/envs/py38/lib/python3.8/site-packages (from sympy->torch>=2.0.1->deepseek_vl==1.0.0) (1.3.0)\n",
            "Collecting torch>=2.0.1 (from deepseek_vl==1.0.0)\n",
            "  Downloading torch-2.4.1-cp38-cp38-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision->timm>=0.9.16->deepseek_vl==1.0.0)\n",
            "  Downloading pillow-10.4.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.0.1->deepseek_vl==1.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.0.1->deepseek_vl==1.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.0.1->deepseek_vl==1.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.1->deepseek_vl==1.0.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.0.1->deepseek_vl==1.0.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.0.1->deepseek_vl==1.0.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.0.1->deepseek_vl==1.0.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.0.1->deepseek_vl==1.0.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.0.1->deepseek_vl==1.0.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.0.1->deepseek_vl==1.0.0)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.0.1->deepseek_vl==1.0.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch>=2.0.1->deepseek_vl==1.0.0)\n",
            "  Downloading triton-3.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.1->deepseek_vl==1.0.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.9.41-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Downloading timm-1.0.15-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m181.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
            "Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
            "Downloading sentencepiece-0.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m131.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading torchvision-0.19.1-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m145.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.4.1-cp38-cp38-manylinux1_x86_64.whl (797.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m177.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m200.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m138.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m150.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m138.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading triton-3.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m120.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m123.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.9.41-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m163.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: deepseek_vl\n",
            "  Building editable for deepseek_vl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepseek_vl: filename=deepseek_vl-1.0.0-0.editable-py3-none-any.whl size=13124 sha256=97d8e21c859184d44b81518296c28324e8d65259c4b5d4b45de175ae261c30ee\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-50mvd4v1/wheels/73/a4/8a/61d46483981a3ac3d4f78116e149261d2935e02916ed472f1a\n",
            "Successfully built deepseek_vl\n",
            "Installing collected packages: sentencepiece, triton, six, psutil, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, einops, nvidia-cusparse-cu12, nvidia-cudnn-cu12, attrdict, tokenizers, nvidia-cusolver-cu12, transformers, torch, torchvision, accelerate, timm, deepseek_vl\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.0.0\n",
            "    Uninstalling triton-2.0.0:\n",
            "      Successfully uninstalled triton-2.0.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.2\n",
            "    Uninstalling tokenizers-0.15.2:\n",
            "      Successfully uninstalled tokenizers-0.15.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.36.2\n",
            "    Uninstalling transformers-4.36.2:\n",
            "      Successfully uninstalled transformers-4.36.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1\n",
            "    Uninstalling torch-2.0.1:\n",
            "      Successfully uninstalled torch-2.0.1\n",
            "Successfully installed accelerate-1.0.1 attrdict-2.0.1 deepseek_vl-1.0.0 einops-0.8.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.41 nvidia-nvtx-cu12-12.1.105 pillow-10.4.0 psutil-7.0.0 sentencepiece-0.2.0 six-1.17.0 timm-1.0.15 tokenizers-0.20.3 torch-2.4.1 torchvision-0.19.1 transformers-4.46.3 triton-3.0.0\n"
          ]
        }
      ],
      "source": [
        "!wget -nc https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "\n",
        "!bash Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.8/site-packages')\n",
        "\n",
        "!conda create -y -n py38 python=3.8\n",
        "\n",
        "!source /usr/local/bin/activate py38 && python --version\n",
        "\n",
        "!source /usr/local/bin/activate py38 && conda install -y pip\n",
        "!source /usr/local/bin/activate py38 && pip install torch==2.0.1 transformers==4.36.2 numpy==1.24.4\n",
        "\n",
        "!git clone https://github.com/deepseek-ai/DeepSeek-VL.git\n",
        "!source /usr/local/bin/activate py38 && pip install -e ./DeepSeek-VL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "VCiqtophjY9H",
        "outputId": "1498e861-c086-4a96-860e-abc81e34d27c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1d22b7e8-2366-4e8a-8ca6-ee02465d6f0a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1d22b7e8-2366-4e8a-8ca6-ee02465d6f0a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Aniline.png to Aniline.png\n",
            "Saving Benzaldehyde.png to Benzaldehyde.png\n",
            "Saving Benzene.png to Benzene.png\n",
            "Saving Benzoic_acid.png to Benzoic_acid.png\n",
            "Saving Caffeine.png to Caffeine.png\n",
            "Saving Morphine.png to Morphine.png\n",
            "Saving Nitrobenzene.png to Nitrobenzene.png\n",
            "Saving Ozone.png to Ozone.png\n",
            "Saving Phenol.png to Phenol.png\n",
            "Saving Pyridine-full.png to Pyridine-full.png\n",
            "Saving Pyrrole-full.png to Pyrrole-full.png\n",
            "Saving Pyrrole-numbered.png to Pyrrole-numbered.png\n",
            "Saving Salicylic-acid.png to Salicylic-acid.png\n",
            "Saving Toluene.png to Toluene.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re1dgvxOlZew",
        "outputId": "fe9ff145-2e55-4c88-c47f-9e0021c9e8f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 149M\n",
            "-rw-r--r-- 1 root root  20K May 11 04:39 Aniline.png\n",
            "-rw-r--r-- 1 root root  29K May 11 04:39 Benzaldehyde.png\n",
            "-rw-r--r-- 1 root root  58K May 11 04:39 Benzene.png\n",
            "-rw-r--r-- 1 root root  30K May 11 04:39 Benzoic_acid.png\n",
            "-rw-r--r-- 1 root root  26K May 11 04:39 Caffeine.png\n",
            "drwxr-xr-x 7 root root 4.0K May 11 04:36 DeepSeek-VL\n",
            "-rw-r--r-- 1 root root 149M Apr 30 20:14 Miniconda3-latest-Linux-x86_64.sh\n",
            "-rw-r--r-- 1 root root  25K May 11 04:39 Morphine.png\n",
            "-rw-r--r-- 1 root root  24K May 11 04:39 Nitrobenzene.png\n",
            "-rw-r--r-- 1 root root  29K May 11 04:39 Ozone.png\n",
            "-rw-r--r-- 1 root root 6.6K May 11 04:39 Phenol.png\n",
            "-rw-r--r-- 1 root root  25K May 11 04:39 Pyridine-full.png\n",
            "-rw-r--r-- 1 root root  24K May 11 04:39 Pyrrole-full.png\n",
            "-rw-r--r-- 1 root root  24K May 11 04:39 Pyrrole-numbered.png\n",
            "-rw-r--r-- 1 root root  28K May 11 04:39 Salicylic-acid.png\n",
            "drwxr-xr-x 1 root root 4.0K May  8 13:38 sample_data\n",
            "-rw-r--r-- 1 root root  23K May 11 04:39 Toluene.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"task1-deepseek.py\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "from transformers import AutoTokenizer, AutoProcessor\n",
        "from deepseek_vl.models import VLChatProcessor, MultiModalityCausalLM\n",
        "from deepseek_vl.utils.io import load_pil_images\n",
        "import torch\n",
        "from PIL import Image\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# ----- 1. Setup Model -----\n",
        "model_id = \"deepseek-ai/deepseek-vl-7b-chat\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = MultiModalityCausalLM.from_pretrained(model_id, trust_remote_code=True).to(torch.bfloat16).cuda().eval()\n",
        "vl_chat_processor = VLChatProcessor.from_pretrained(model_id)\n",
        "tokenizer = vl_chat_processor.tokenizer\n",
        "\n",
        "# ----- 2. Define CoT Templates -----\n",
        "prompts = {\n",
        "    \"baseline\": \"Which molecule is more reactive toward electrophilic aromatic substitution, the first or the second? Why?\",\n",
        "    \"stepwise\": \"First, note if the ring has electron-donating substituents. Then, note if it has electron-withdrawing substituents. Finally, determine which ring is more reactive toward electrophiles.\",\n",
        "    \"visual_first\": \"Observe visible features: are there -OH, -NH₂, or -NO₂ groups? Count and compare electron-donating versus electron-withdrawing groups for both molecules.\",\n",
        "    \"explanation_first\": \"Consider the net electronic effect (donating vs withdrawing) based on the visible substituents. Then predict which molecule will react faster toward EAS.\"\n",
        "}\n",
        "\n",
        "# ----- 3. Define Image Pairs -----\n",
        "dataset_folder = \"/content\"\n",
        "image_pairs = [\n",
        "    (\"Aniline.png\", \"Nitrobenzene.png\"),\n",
        "    (\"Benzene.png\", \"Toluene.png\"),\n",
        "    (\"Benzaldehyde.png\", \"Benzoic_acid.png\"),\n",
        "    (\"Pyridine-full.png\", \"Benzene.png\"),\n",
        "    (\"Pyrrole-full.png\", \"Benzene.png\"),\n",
        "    (\"Phenol.png\", \"Benzene.png\"),\n",
        "    (\"Salicylic-acid.png\", \"Benzoic_acid.png\"),\n",
        "    (\"Nitrobenzene.png\", \"Ozone.png\"),\n",
        "    (\"Pyrrole-numbered.png\", \"Pyridine-full.png\"),\n",
        "    (\"Morphine.png\", \"Caffeine.png\")\n",
        "]\n",
        "\n",
        "# ----- 4. Output Setup -----\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "csv_file = open(\"outputs/Task1_deepseek_outputs.csv\", \"w\", encoding=\"utf-8\", newline=\"\")\n",
        "writer = csv.DictWriter(csv_file, fieldnames=[\"image1\", \"image2\", \"prompt_type\", \"prompt_text\", \"generated_text\"])\n",
        "writer.writeheader()\n",
        "\n",
        "# ----- 5. Inference -----\n",
        "for img1, img2 in image_pairs:\n",
        "    img_path1 = os.path.join(dataset_folder, img1)\n",
        "    img_path2 = os.path.join(dataset_folder, img2)\n",
        "    for prompt_type, prompt_template in prompts.items():\n",
        "        conversation = [\n",
        "            {\n",
        "                \"role\": \"User\",\n",
        "                \"content\": prompt_template,\n",
        "                \"images\": [img_path1, img_path2]\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"Assistant\",\n",
        "                \"content\": \"\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        images = load_pil_images(conversation)\n",
        "        prepare_inputs = vl_chat_processor(\n",
        "            conversations=conversation,\n",
        "            images=images,\n",
        "            force_batchify=True\n",
        "        ).to(model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs_embeds = model.prepare_inputs_embeds(**prepare_inputs)\n",
        "            outputs = model.language_model.generate(\n",
        "                inputs_embeds=inputs_embeds,\n",
        "                attention_mask=prepare_inputs.attention_mask,\n",
        "                pad_token_id=tokenizer.eos_token_id,\n",
        "                bos_token_id=tokenizer.bos_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id,\n",
        "                max_new_tokens=512,\n",
        "                do_sample=False,\n",
        "                use_cache=True\n",
        "            )\n",
        "\n",
        "        answer = tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=True)\n",
        "        print(f\"--- Finished {prompt_type} for {img1} and {img2}\")\n",
        "        writer.writerow({\n",
        "            \"image1\": img1,\n",
        "            \"image2\": img2,\n",
        "            \"prompt_type\": prompt_type,\n",
        "            \"prompt_text\": prompt_template,\n",
        "            \"generated_text\": answer.strip()\n",
        "        })\n",
        "\n",
        "csv_file.close()\n",
        "print(\"!!!! All pair inference completed and saved to outputs/Task1_deepseek_outputs.csv\")\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "m_iOp-3ONmBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!source /usr/local/bin/activate py38 && python task1-deepseek.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daTuou9IjzGo",
        "outputId": "f7a0886d-efc1-40eb-846d-bfc926d2e285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/envs/py38/lib/python3.8/site-packages/transformers/models/auto/image_processing_auto.py:520: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
            "  warnings.warn(\n",
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "config.json: 100% 1.54k/1.54k [00:00<00:00, 257kB/s]\n",
            "model.safetensors.index.json: 100% 81.1k/81.1k [00:00<00:00, 13.9MB/s]\n",
            "Downloading shards:   0% 0/3 [00:00<?, ?it/s]\n",
            "model-00001-of-00003.safetensors:   0% 0.00/4.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   0% 21.0M/4.98G [00:00<00:27, 183MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   1% 62.9M/4.98G [00:00<00:18, 269MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   2% 94.4M/4.98G [00:00<00:22, 215MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   3% 126M/4.98G [00:00<00:21, 222MB/s] \u001b[A\n",
            "model-00001-of-00003.safetensors:   3% 157M/4.98G [00:00<00:20, 237MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   4% 189M/4.98G [00:00<00:18, 254MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   4% 220M/4.98G [00:00<00:18, 261MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   5% 252M/4.98G [00:01<00:18, 256MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   6% 294M/4.98G [00:01<00:17, 265MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   7% 325M/4.98G [00:01<00:18, 252MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   7% 357M/4.98G [00:01<00:17, 267MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   8% 388M/4.98G [00:01<00:17, 260MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   8% 419M/4.98G [00:01<00:16, 271MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:   9% 451M/4.98G [00:01<00:17, 264MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  10% 482M/4.98G [00:01<00:17, 264MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  10% 514M/4.98G [00:02<00:16, 272MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  11% 556M/4.98G [00:02<00:15, 287MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  12% 587M/4.98G [00:02<00:14, 293MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  12% 619M/4.98G [00:02<00:15, 287MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  13% 661M/4.98G [00:02<00:14, 298MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  14% 692M/4.98G [00:02<00:15, 275MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  15% 724M/4.98G [00:02<00:15, 277MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  15% 755M/4.98G [00:02<00:15, 264MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  16% 797M/4.98G [00:03<00:15, 272MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  17% 828M/4.98G [00:03<00:14, 279MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  17% 860M/4.98G [00:03<00:14, 277MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  18% 902M/4.98G [00:03<00:13, 294MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  19% 944M/4.98G [00:03<00:13, 295MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  20% 975M/4.98G [00:03<00:13, 286MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  20% 1.01G/4.98G [00:03<00:13, 284MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  21% 1.04G/4.98G [00:03<00:13, 292MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  21% 1.07G/4.98G [00:03<00:13, 287MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  22% 1.10G/4.98G [00:04<00:14, 272MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  23% 1.13G/4.98G [00:04<00:14, 269MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  23% 1.16G/4.98G [00:04<00:14, 264MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  24% 1.20G/4.98G [00:04<00:14, 263MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  25% 1.24G/4.98G [00:04<00:12, 293MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  25% 1.27G/4.98G [00:04<00:12, 288MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  26% 1.31G/4.98G [00:04<00:12, 304MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  27% 1.34G/4.98G [00:04<00:13, 278MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  28% 1.37G/4.98G [00:05<00:12, 282MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  28% 1.41G/4.98G [00:05<00:13, 261MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  29% 1.44G/4.98G [00:05<00:14, 246MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  29% 1.47G/4.98G [00:05<00:13, 253MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  30% 1.51G/4.98G [00:05<00:13, 266MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  31% 1.54G/4.98G [00:05<00:12, 272MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  32% 1.57G/4.98G [00:05<00:13, 259MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  32% 1.60G/4.98G [00:05<00:13, 258MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  33% 1.64G/4.98G [00:06<00:13, 249MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  33% 1.67G/4.98G [00:06<00:12, 262MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  34% 1.70G/4.98G [00:06<00:12, 270MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  35% 1.73G/4.98G [00:06<00:12, 253MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  35% 1.76G/4.98G [00:06<00:12, 266MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  36% 1.79G/4.98G [00:06<00:14, 226MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  37% 1.82G/4.98G [00:06<00:13, 240MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  37% 1.86G/4.98G [00:06<00:12, 244MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  38% 1.89G/4.98G [00:07<00:12, 255MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  39% 1.92G/4.98G [00:07<00:11, 259MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  39% 1.96G/4.98G [00:07<00:11, 273MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  40% 1.99G/4.98G [00:07<00:10, 272MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  41% 2.02G/4.98G [00:07<00:10, 274MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  41% 2.06G/4.98G [00:07<00:10, 284MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  42% 2.10G/4.98G [00:07<00:09, 294MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  43% 2.13G/4.98G [00:07<00:09, 299MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  43% 2.16G/4.98G [00:08<00:09, 289MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  44% 2.19G/4.98G [00:08<00:12, 228MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  45% 2.22G/4.98G [00:08<00:13, 211MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  45% 2.25G/4.98G [00:08<00:12, 221MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  46% 2.29G/4.98G [00:08<00:11, 236MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  47% 2.32G/4.98G [00:08<00:11, 242MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  47% 2.35G/4.98G [00:08<00:10, 245MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  48% 2.38G/4.98G [00:09<00:10, 237MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  49% 2.42G/4.98G [00:09<00:09, 257MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  49% 2.45G/4.98G [00:09<00:09, 263MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  50% 2.49G/4.98G [00:09<00:09, 253MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  51% 2.52G/4.98G [00:09<00:09, 265MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  51% 2.56G/4.98G [00:09<00:08, 286MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  52% 2.59G/4.98G [00:09<00:08, 288MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  53% 2.62G/4.98G [00:09<00:08, 281MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  53% 2.65G/4.98G [00:09<00:08, 287MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  54% 2.68G/4.98G [00:10<00:07, 291MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  55% 2.72G/4.98G [00:10<00:11, 194MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  55% 2.75G/4.98G [00:10<00:10, 216MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  56% 2.78G/4.98G [00:10<00:09, 232MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  56% 2.81G/4.98G [00:10<00:09, 233MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  57% 2.84G/4.98G [00:11<00:14, 145MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  58% 2.87G/4.98G [00:11<00:12, 171MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  58% 2.90G/4.98G [00:11<00:15, 136MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  59% 2.93G/4.98G [00:11<00:16, 123MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  59% 2.96G/4.98G [00:11<00:13, 149MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  60% 2.98G/4.98G [00:12<00:14, 141MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  60% 3.01G/4.98G [00:12<00:12, 163MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  61% 3.05G/4.98G [00:12<00:09, 200MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  62% 3.08G/4.98G [00:12<00:08, 217MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  63% 3.11G/4.98G [00:12<00:07, 235MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  63% 3.15G/4.98G [00:12<00:07, 230MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  64% 3.18G/4.98G [00:12<00:09, 185MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  64% 3.21G/4.98G [00:13<00:09, 187MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  65% 3.23G/4.98G [00:13<00:10, 167MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  65% 3.25G/4.98G [00:13<00:12, 134MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  66% 3.27G/4.98G [00:13<00:12, 135MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  66% 3.29G/4.98G [00:13<00:14, 120MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  67% 3.31G/4.98G [00:14<00:12, 130MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  67% 3.36G/4.98G [00:14<00:09, 173MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  68% 3.39G/4.98G [00:14<00:08, 198MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  69% 3.42G/4.98G [00:14<00:07, 222MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  70% 3.46G/4.98G [00:14<00:05, 257MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  70% 3.49G/4.98G [00:14<00:05, 263MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  71% 3.52G/4.98G [00:14<00:05, 255MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  72% 3.57G/4.98G [00:14<00:05, 276MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  72% 3.60G/4.98G [00:15<00:04, 278MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  73% 3.65G/4.98G [00:15<00:04, 317MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  74% 3.69G/4.98G [00:15<00:03, 326MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  75% 3.73G/4.98G [00:15<00:03, 328MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  76% 3.77G/4.98G [00:15<00:03, 320MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  77% 3.82G/4.98G [00:15<00:03, 324MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  78% 3.86G/4.98G [00:15<00:03, 321MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  78% 3.90G/4.98G [00:15<00:03, 322MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  79% 3.94G/4.98G [00:16<00:03, 324MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  80% 3.98G/4.98G [00:16<00:03, 329MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  81% 4.03G/4.98G [00:16<00:03, 311MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  82% 4.06G/4.98G [00:16<00:03, 306MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  82% 4.10G/4.98G [00:16<00:02, 325MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  83% 4.14G/4.98G [00:16<00:02, 325MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  84% 4.18G/4.98G [00:16<00:02, 314MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  85% 4.23G/4.98G [00:16<00:02, 322MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  86% 4.27G/4.98G [00:17<00:02, 322MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  87% 4.31G/4.98G [00:17<00:02, 330MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  87% 4.35G/4.98G [00:17<00:02, 298MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  88% 4.38G/4.98G [00:17<00:02, 282MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  89% 4.41G/4.98G [00:17<00:02, 271MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  89% 4.45G/4.98G [00:17<00:02, 264MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  90% 4.49G/4.98G [00:17<00:01, 269MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  91% 4.52G/4.98G [00:18<00:01, 277MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  92% 4.56G/4.98G [00:18<00:01, 293MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  92% 4.59G/4.98G [00:18<00:01, 294MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  93% 4.62G/4.98G [00:18<00:01, 298MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  94% 4.67G/4.98G [00:18<00:01, 306MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  95% 4.71G/4.98G [00:18<00:00, 314MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  95% 4.75G/4.98G [00:18<00:00, 321MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  96% 4.79G/4.98G [00:18<00:00, 319MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  97% 4.83G/4.98G [00:19<00:00, 316MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  98% 4.88G/4.98G [00:19<00:00, 327MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors:  99% 4.92G/4.98G [00:19<00:00, 323MB/s]\u001b[A\n",
            "model-00001-of-00003.safetensors: 100% 4.98G/4.98G [00:19<00:00, 256MB/s]\n",
            "Downloading shards:  33% 1/3 [00:19<00:39, 19.74s/it]\n",
            "model-00002-of-00003.safetensors:   0% 0.00/4.96G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   1% 31.5M/4.96G [00:00<00:15, 311MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   1% 73.4M/4.96G [00:00<00:14, 326MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   2% 115M/4.96G [00:00<00:13, 359MB/s] \u001b[A\n",
            "model-00002-of-00003.safetensors:   3% 157M/4.96G [00:00<00:14, 332MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   4% 199M/4.96G [00:00<00:15, 310MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   5% 241M/4.96G [00:00<00:14, 318MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   6% 283M/4.96G [00:00<00:15, 308MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   6% 315M/4.96G [00:01<00:15, 297MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   7% 346M/4.96G [00:01<00:17, 269MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   8% 377M/4.96G [00:01<00:17, 267MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   8% 409M/4.96G [00:01<00:17, 261MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:   9% 440M/4.96G [00:01<00:16, 267MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  10% 472M/4.96G [00:01<00:16, 273MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  10% 503M/4.96G [00:01<00:16, 275MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  11% 535M/4.96G [00:01<00:16, 271MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  11% 566M/4.96G [00:01<00:16, 267MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  12% 598M/4.96G [00:02<00:16, 268MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  13% 629M/4.96G [00:02<00:16, 269MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  13% 661M/4.96G [00:02<00:19, 221MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  14% 692M/4.96G [00:02<00:17, 243MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  15% 734M/4.96G [00:02<00:16, 253MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  16% 776M/4.96G [00:02<00:15, 274MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  16% 807M/4.96G [00:02<00:15, 272MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  17% 849M/4.96G [00:03<00:14, 289MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  18% 891M/4.96G [00:03<00:13, 306MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  19% 933M/4.96G [00:03<00:12, 327MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  20% 975M/4.96G [00:03<00:13, 295MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  20% 1.01G/4.96G [00:03<00:15, 256MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  21% 1.04G/4.96G [00:03<00:17, 227MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  22% 1.07G/4.96G [00:03<00:18, 210MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  22% 1.10G/4.96G [00:04<00:19, 199MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  23% 1.12G/4.96G [00:04<00:19, 198MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  23% 1.14G/4.96G [00:04<00:22, 171MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  24% 1.17G/4.96G [00:04<00:19, 194MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  25% 1.22G/4.96G [00:04<00:16, 232MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  25% 1.25G/4.96G [00:04<00:15, 236MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  26% 1.28G/4.96G [00:04<00:15, 241MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  26% 1.31G/4.96G [00:05<00:14, 256MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  27% 1.34G/4.96G [00:05<00:13, 259MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  28% 1.38G/4.96G [00:05<00:12, 285MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  29% 1.43G/4.96G [00:05<00:12, 291MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  29% 1.46G/4.96G [00:05<00:12, 282MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  30% 1.49G/4.96G [00:05<00:12, 274MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  31% 1.53G/4.96G [00:05<00:11, 295MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  32% 1.56G/4.96G [00:05<00:12, 278MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  32% 1.60G/4.96G [00:06<00:11, 285MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  33% 1.64G/4.96G [00:06<00:12, 266MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  34% 1.67G/4.96G [00:06<00:12, 267MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  34% 1.70G/4.96G [00:06<00:13, 243MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  35% 1.73G/4.96G [00:06<00:14, 221MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  36% 1.76G/4.96G [00:06<00:15, 210MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  36% 1.79G/4.96G [00:07<00:21, 148MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  37% 1.81G/4.96G [00:07<00:20, 157MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  37% 1.85G/4.96G [00:07<00:17, 178MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  38% 1.88G/4.96G [00:07<00:16, 183MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  38% 1.90G/4.96G [00:07<00:16, 183MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  39% 1.92G/4.96G [00:07<00:16, 181MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  39% 1.94G/4.96G [00:07<00:16, 186MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  40% 1.96G/4.96G [00:08<00:16, 180MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  40% 1.98G/4.96G [00:08<00:19, 151MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  40% 2.00G/4.96G [00:08<00:23, 127MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  41% 2.02G/4.96G [00:08<00:21, 139MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  41% 2.04G/4.96G [00:08<00:19, 150MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  42% 2.07G/4.96G [00:08<00:19, 151MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  42% 2.09G/4.96G [00:08<00:18, 152MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  43% 2.11G/4.96G [00:09<00:17, 160MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  43% 2.14G/4.96G [00:09<00:14, 191MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  44% 2.17G/4.96G [00:09<00:13, 211MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  45% 2.21G/4.96G [00:09<00:11, 248MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  45% 2.24G/4.96G [00:09<00:11, 245MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  46% 2.28G/4.96G [00:09<00:10, 261MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  47% 2.31G/4.96G [00:09<00:10, 249MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  47% 2.34G/4.96G [00:09<00:11, 238MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  48% 2.38G/4.96G [00:10<00:09, 261MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  49% 2.41G/4.96G [00:10<00:09, 269MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  49% 2.44G/4.96G [00:10<00:09, 275MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  50% 2.49G/4.96G [00:10<00:08, 295MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  51% 2.53G/4.96G [00:10<00:07, 310MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  52% 2.57G/4.96G [00:10<00:07, 310MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  53% 2.61G/4.96G [00:10<00:07, 312MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  53% 2.64G/4.96G [00:10<00:07, 302MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  54% 2.68G/4.96G [00:11<00:07, 320MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  55% 2.73G/4.96G [00:11<00:07, 307MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  56% 2.77G/4.96G [00:11<00:07, 308MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  56% 2.80G/4.96G [00:11<00:07, 275MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  57% 2.83G/4.96G [00:11<00:08, 244MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  58% 2.86G/4.96G [00:11<00:09, 232MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  58% 2.89G/4.96G [00:11<00:08, 240MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  59% 2.93G/4.96G [00:12<00:08, 235MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  60% 2.96G/4.96G [00:12<00:08, 250MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  60% 2.99G/4.96G [00:12<00:08, 219MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  61% 3.02G/4.96G [00:12<00:09, 212MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  62% 3.05G/4.96G [00:12<00:09, 208MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  62% 3.08G/4.96G [00:12<00:08, 220MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  63% 3.11G/4.96G [00:12<00:08, 212MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  63% 3.15G/4.96G [00:13<00:11, 155MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  64% 3.18G/4.96G [00:13<00:10, 169MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  65% 3.20G/4.96G [00:13<00:09, 176MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  65% 3.24G/4.96G [00:13<00:07, 216MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  66% 3.27G/4.96G [00:13<00:07, 231MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  67% 3.30G/4.96G [00:13<00:07, 233MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  67% 3.34G/4.96G [00:14<00:06, 259MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  68% 3.39G/4.96G [00:14<00:05, 283MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  69% 3.43G/4.96G [00:14<00:05, 296MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  70% 3.46G/4.96G [00:14<00:05, 299MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  70% 3.49G/4.96G [00:14<00:05, 289MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  71% 3.53G/4.96G [00:14<00:04, 301MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  72% 3.57G/4.96G [00:14<00:05, 273MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  73% 3.61G/4.96G [00:14<00:04, 293MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  73% 3.64G/4.96G [00:15<00:04, 295MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  74% 3.67G/4.96G [00:15<00:04, 298MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  75% 3.71G/4.96G [00:15<00:03, 326MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  76% 3.75G/4.96G [00:15<00:03, 318MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  77% 3.80G/4.96G [00:15<00:03, 306MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  77% 3.83G/4.96G [00:15<00:03, 305MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  78% 3.86G/4.96G [00:15<00:03, 304MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  78% 3.89G/4.96G [00:15<00:03, 299MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  79% 3.92G/4.96G [00:15<00:03, 300MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  80% 3.95G/4.96G [00:16<00:03, 292MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  80% 3.98G/4.96G [00:16<00:03, 278MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  81% 4.02G/4.96G [00:16<00:03, 272MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  82% 4.05G/4.96G [00:16<00:03, 271MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  82% 4.08G/4.96G [00:16<00:03, 275MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  83% 4.11G/4.96G [00:16<00:03, 223MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  84% 4.14G/4.96G [00:16<00:03, 225MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  84% 4.18G/4.96G [00:16<00:03, 252MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  85% 4.22G/4.96G [00:17<00:02, 254MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  86% 4.25G/4.96G [00:17<00:02, 268MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  86% 4.28G/4.96G [00:17<00:02, 279MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  87% 4.31G/4.96G [00:17<00:02, 285MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  88% 4.34G/4.96G [00:17<00:02, 281MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  88% 4.38G/4.96G [00:17<00:01, 297MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  89% 4.41G/4.96G [00:17<00:01, 296MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  90% 4.45G/4.96G [00:17<00:01, 282MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  90% 4.48G/4.96G [00:18<00:01, 288MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  91% 4.51G/4.96G [00:18<00:01, 293MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  92% 4.54G/4.96G [00:18<00:01, 296MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  92% 4.57G/4.96G [00:18<00:01, 288MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  93% 4.60G/4.96G [00:18<00:01, 266MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  93% 4.63G/4.96G [00:18<00:01, 261MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  94% 4.67G/4.96G [00:18<00:01, 257MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  95% 4.70G/4.96G [00:18<00:00, 267MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  95% 4.73G/4.96G [00:19<00:01, 202MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  96% 4.76G/4.96G [00:19<00:01, 165MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  96% 4.78G/4.96G [00:19<00:01, 170MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  97% 4.81G/4.96G [00:19<00:00, 152MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  98% 4.83G/4.96G [00:19<00:00, 150MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  98% 4.85G/4.96G [00:20<00:00, 120MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  98% 4.88G/4.96G [00:20<00:00, 109MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  99% 4.90G/4.96G [00:20<00:00, 121MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors:  99% 4.92G/4.96G [00:20<00:00, 129MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors: 100% 4.94G/4.96G [00:20<00:00, 122MB/s]\u001b[A\n",
            "model-00002-of-00003.safetensors: 100% 4.96G/4.96G [00:20<00:00, 236MB/s]\n",
            "Downloading shards:  67% 2/3 [00:40<00:20, 20.62s/it]\n",
            "model-00003-of-00003.safetensors:   0% 0.00/4.75G [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   0% 21.0M/4.75G [00:00<00:23, 204MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   1% 62.9M/4.75G [00:00<00:15, 303MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   2% 94.4M/4.75G [00:00<00:16, 286MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   3% 136M/4.75G [00:00<00:15, 300MB/s] \u001b[A\n",
            "model-00003-of-00003.safetensors:   4% 168M/4.75G [00:00<00:15, 289MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   4% 199M/4.75G [00:00<00:20, 218MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   5% 231M/4.75G [00:00<00:19, 228MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   6% 262M/4.75G [00:01<00:20, 219MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   6% 294M/4.75G [00:01<00:21, 207MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   7% 325M/4.75G [00:01<00:19, 225MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   8% 357M/4.75G [00:01<00:18, 241MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   8% 388M/4.75G [00:01<00:18, 238MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:   9% 430M/4.75G [00:01<00:15, 270MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  10% 461M/4.75G [00:01<00:15, 280MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  10% 493M/4.75G [00:01<00:15, 275MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  11% 524M/4.75G [00:02<00:15, 271MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  12% 556M/4.75G [00:02<00:14, 280MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  12% 587M/4.75G [00:02<00:15, 276MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  13% 619M/4.75G [00:02<00:16, 256MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  14% 650M/4.75G [00:02<00:15, 257MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  14% 682M/4.75G [00:02<00:15, 266MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  15% 713M/4.75G [00:02<00:14, 273MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  16% 744M/4.75G [00:02<00:14, 283MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  16% 776M/4.75G [00:03<00:15, 249MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  17% 807M/4.75G [00:03<00:14, 264MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  18% 839M/4.75G [00:03<00:14, 274MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  18% 870M/4.75G [00:03<00:13, 278MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  19% 912M/4.75G [00:03<00:12, 301MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  20% 954M/4.75G [00:03<00:12, 306MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  21% 996M/4.75G [00:03<00:11, 314MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  22% 1.04G/4.75G [00:03<00:13, 286MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  23% 1.07G/4.75G [00:04<00:12, 290MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  23% 1.10G/4.75G [00:04<00:12, 294MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  24% 1.13G/4.75G [00:04<00:12, 299MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  24% 1.16G/4.75G [00:04<00:12, 283MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  25% 1.20G/4.75G [00:04<00:12, 274MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  26% 1.23G/4.75G [00:04<00:12, 280MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  26% 1.26G/4.75G [00:04<00:13, 268MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  27% 1.29G/4.75G [00:04<00:13, 253MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  28% 1.33G/4.75G [00:04<00:12, 281MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  29% 1.37G/4.75G [00:05<00:11, 304MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  30% 1.41G/4.75G [00:05<00:11, 303MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  30% 1.44G/4.75G [00:05<00:11, 297MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  31% 1.48G/4.75G [00:05<00:10, 312MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  32% 1.51G/4.75G [00:05<00:10, 311MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  33% 1.55G/4.75G [00:05<00:10, 317MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  34% 1.59G/4.75G [00:05<00:10, 314MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  34% 1.63G/4.75G [00:05<00:10, 305MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  35% 1.66G/4.75G [00:05<00:10, 304MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  36% 1.70G/4.75G [00:06<00:09, 314MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  37% 1.74G/4.75G [00:06<00:09, 321MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  38% 1.78G/4.75G [00:06<00:09, 309MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  38% 1.82G/4.75G [00:06<00:09, 316MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  39% 1.87G/4.75G [00:06<00:09, 316MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  40% 1.91G/4.75G [00:06<00:09, 306MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  41% 1.95G/4.75G [00:06<00:08, 313MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  42% 1.98G/4.75G [00:07<00:09, 302MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  42% 2.01G/4.75G [00:07<00:09, 300MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  43% 2.06G/4.75G [00:07<00:08, 314MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  44% 2.10G/4.75G [00:07<00:08, 312MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  45% 2.14G/4.75G [00:07<00:08, 309MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  46% 2.18G/4.75G [00:07<00:08, 316MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  47% 2.22G/4.75G [00:07<00:07, 319MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  48% 2.26G/4.75G [00:07<00:07, 328MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  49% 2.31G/4.75G [00:08<00:07, 320MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  49% 2.35G/4.75G [00:08<00:07, 319MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  50% 2.39G/4.75G [00:08<00:07, 312MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  51% 2.42G/4.75G [00:08<00:07, 296MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  52% 2.46G/4.75G [00:08<00:07, 293MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  53% 2.50G/4.75G [00:08<00:07, 290MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  53% 2.53G/4.75G [00:08<00:07, 289MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  54% 2.56G/4.75G [00:08<00:08, 270MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  54% 2.59G/4.75G [00:09<00:07, 279MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  55% 2.63G/4.75G [00:09<00:07, 299MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  56% 2.66G/4.75G [00:09<00:07, 294MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  57% 2.69G/4.75G [00:09<00:07, 283MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  57% 2.73G/4.75G [00:09<00:07, 282MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  58% 2.76G/4.75G [00:09<00:06, 290MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  59% 2.79G/4.75G [00:09<00:07, 276MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  59% 2.82G/4.75G [00:09<00:07, 271MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  60% 2.86G/4.75G [00:09<00:06, 296MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  61% 2.89G/4.75G [00:10<00:06, 300MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  62% 2.93G/4.75G [00:10<00:07, 248MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  62% 2.96G/4.75G [00:10<00:07, 229MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  63% 2.99G/4.75G [00:10<00:10, 172MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  63% 3.01G/4.75G [00:10<00:10, 165MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  64% 3.05G/4.75G [00:11<00:08, 205MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  65% 3.08G/4.75G [00:11<00:07, 224MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  66% 3.11G/4.75G [00:11<00:06, 240MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  66% 3.15G/4.75G [00:11<00:06, 246MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  67% 3.18G/4.75G [00:11<00:07, 225MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  68% 3.21G/4.75G [00:11<00:08, 191MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  68% 3.23G/4.75G [00:11<00:09, 166MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  68% 3.25G/4.75G [00:12<00:09, 161MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  69% 3.28G/4.75G [00:12<00:09, 158MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  70% 3.31G/4.75G [00:12<00:09, 150MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  70% 3.33G/4.75G [00:12<00:09, 153MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  71% 3.38G/4.75G [00:12<00:07, 196MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  72% 3.41G/4.75G [00:13<00:08, 156MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  72% 3.43G/4.75G [00:13<00:08, 155MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  73% 3.45G/4.75G [00:13<00:08, 162MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  73% 3.47G/4.75G [00:13<00:07, 168MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  74% 3.51G/4.75G [00:13<00:06, 193MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  74% 3.53G/4.75G [00:13<00:06, 196MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  75% 3.55G/4.75G [00:13<00:06, 183MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  75% 3.58G/4.75G [00:13<00:06, 170MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  76% 3.61G/4.75G [00:14<00:05, 204MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  77% 3.64G/4.75G [00:14<00:04, 228MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  77% 3.67G/4.75G [00:14<00:04, 248MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  78% 3.70G/4.75G [00:14<00:04, 238MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  79% 3.73G/4.75G [00:14<00:04, 216MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  79% 3.76G/4.75G [00:14<00:04, 230MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  80% 3.80G/4.75G [00:14<00:04, 213MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  81% 3.83G/4.75G [00:15<00:04, 221MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  81% 3.86G/4.75G [00:15<00:03, 238MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  82% 3.90G/4.75G [00:15<00:03, 266MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  83% 3.93G/4.75G [00:15<00:02, 275MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  83% 3.96G/4.75G [00:15<00:02, 281MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  84% 4.01G/4.75G [00:15<00:02, 281MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  85% 4.04G/4.75G [00:15<00:02, 284MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  86% 4.07G/4.75G [00:15<00:02, 282MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  86% 4.10G/4.75G [00:15<00:02, 289MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  87% 4.13G/4.75G [00:16<00:02, 260MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  88% 4.16G/4.75G [00:16<00:02, 264MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  88% 4.19G/4.75G [00:16<00:02, 274MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  89% 4.24G/4.75G [00:16<00:01, 290MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  90% 4.27G/4.75G [00:16<00:01, 270MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  90% 4.30G/4.75G [00:16<00:01, 262MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  91% 4.33G/4.75G [00:16<00:01, 267MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  92% 4.37G/4.75G [00:16<00:01, 292MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  93% 4.40G/4.75G [00:17<00:01, 283MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  93% 4.44G/4.75G [00:17<00:01, 277MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  94% 4.48G/4.75G [00:17<00:00, 300MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  95% 4.52G/4.75G [00:17<00:00, 312MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  96% 4.56G/4.75G [00:17<00:00, 315MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  97% 4.60G/4.75G [00:17<00:00, 308MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  98% 4.63G/4.75G [00:17<00:00, 289MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  98% 4.67G/4.75G [00:17<00:00, 292MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors:  99% 4.71G/4.75G [00:18<00:00, 307MB/s]\u001b[A\n",
            "model-00003-of-00003.safetensors: 100% 4.75G/4.75G [00:18<00:00, 261MB/s]\n",
            "Downloading shards: 100% 3/3 [00:59<00:00, 19.80s/it]\n",
            "Loading checkpoint shards: 100% 3/3 [00:05<00:00,  1.71s/it]\n",
            "preprocessor_config.json: 100% 389/389 [00:00<00:00, 237kB/s]\n",
            "tokenizer_config.json: 100% 3.24k/3.24k [00:00<00:00, 2.13MB/s]\n",
            "tokenizer.json: 100% 4.61M/4.61M [00:00<00:00, 6.65MB/s]\n",
            "special_tokens_map.json: 100% 287/287 [00:00<00:00, 162kB/s]\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n",
            "processor_config.json: 100% 210/210 [00:00<00:00, 126kB/s]\n",
            "Some kwargs in processor config are unused and will not have any effect: add_special_token, image_tag, sft_format, ignore_id, num_image_tokens, mask_prompt. \n",
            "--- Finished baseline for Aniline.png and Nitrobenzene.png\n",
            "--- Finished stepwise for Aniline.png and Nitrobenzene.png\n",
            "--- Finished visual_first for Aniline.png and Nitrobenzene.png\n",
            "--- Finished explanation_first for Aniline.png and Nitrobenzene.png\n",
            "--- Finished baseline for Benzene.png and Toluene.png\n",
            "--- Finished stepwise for Benzene.png and Toluene.png\n",
            "--- Finished visual_first for Benzene.png and Toluene.png\n",
            "--- Finished explanation_first for Benzene.png and Toluene.png\n",
            "--- Finished baseline for Benzaldehyde.png and Benzoic_acid.png\n",
            "--- Finished stepwise for Benzaldehyde.png and Benzoic_acid.png\n",
            "--- Finished visual_first for Benzaldehyde.png and Benzoic_acid.png\n",
            "--- Finished explanation_first for Benzaldehyde.png and Benzoic_acid.png\n",
            "--- Finished baseline for Pyridine-full.png and Benzene.png\n",
            "--- Finished stepwise for Pyridine-full.png and Benzene.png\n",
            "--- Finished visual_first for Pyridine-full.png and Benzene.png\n",
            "--- Finished explanation_first for Pyridine-full.png and Benzene.png\n",
            "--- Finished baseline for Pyrrole-full.png and Benzene.png\n",
            "--- Finished stepwise for Pyrrole-full.png and Benzene.png\n",
            "--- Finished visual_first for Pyrrole-full.png and Benzene.png\n",
            "--- Finished explanation_first for Pyrrole-full.png and Benzene.png\n",
            "--- Finished baseline for Phenol.png and Benzene.png\n",
            "--- Finished stepwise for Phenol.png and Benzene.png\n",
            "--- Finished visual_first for Phenol.png and Benzene.png\n",
            "--- Finished explanation_first for Phenol.png and Benzene.png\n",
            "--- Finished baseline for Salicylic-acid.png and Benzoic_acid.png\n",
            "--- Finished stepwise for Salicylic-acid.png and Benzoic_acid.png\n",
            "--- Finished visual_first for Salicylic-acid.png and Benzoic_acid.png\n",
            "--- Finished explanation_first for Salicylic-acid.png and Benzoic_acid.png\n",
            "--- Finished baseline for Nitrobenzene.png and Ozone.png\n",
            "--- Finished stepwise for Nitrobenzene.png and Ozone.png\n",
            "--- Finished visual_first for Nitrobenzene.png and Ozone.png\n",
            "--- Finished explanation_first for Nitrobenzene.png and Ozone.png\n",
            "--- Finished baseline for Pyrrole-numbered.png and Pyridine-full.png\n",
            "--- Finished stepwise for Pyrrole-numbered.png and Pyridine-full.png\n",
            "--- Finished visual_first for Pyrrole-numbered.png and Pyridine-full.png\n",
            "--- Finished explanation_first for Pyrrole-numbered.png and Pyridine-full.png\n",
            "--- Finished baseline for Morphine.png and Caffeine.png\n",
            "--- Finished stepwise for Morphine.png and Caffeine.png\n",
            "--- Finished visual_first for Morphine.png and Caffeine.png\n",
            "--- Finished explanation_first for Morphine.png and Caffeine.png\n",
            "!!!! All pair inference completed and saved to outputs/Task1_deepseek_outputs.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/outputs/Task1_deepseek_outputs.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_bDiRPjnqmVv",
        "outputId": "7af316c7-5c4a-4516-8cf6-6306a40cad4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_64561204-b518-42bf-89e1-5c32933618d0\", \"Task1_deepseek_outputs.csv\", 51492)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"task1-deepseek-finetune.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\"\"\n",
        "from transformers import AutoTokenizer\n",
        "from deepseek_vl.models import VLChatProcessor, MultiModalityCausalLM\n",
        "from deepseek_vl.utils.io import load_pil_images\n",
        "import torch\n",
        "from PIL import Image\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# ----- 1. Setup Model -----\n",
        "model_id = \"deepseek-ai/deepseek-vl-7b-chat\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = MultiModalityCausalLM.from_pretrained(model_id, trust_remote_code=True).to(torch.bfloat16).cuda().eval()\n",
        "vl_chat_processor = VLChatProcessor.from_pretrained(model_id)\n",
        "tokenizer = vl_chat_processor.tokenizer\n",
        "\n",
        "# ----- 2. Define Prompts (Baseline + 15 CoT prompts) -----\n",
        "baseline_prompt = [\"Which molecule is more reactive toward electrophilic aromatic substitution, the first or the second? Why?\"]\n",
        "\n",
        "stepwise_prompts = [\n",
        "    \"First, note if the ring has electron-donating substituents. Then, note if it has electron-withdrawing substituents. Finally, determine which ring is more reactive toward electrophiles.\",\n",
        "    \"Step 1: Look at functional groups. Step 2: Predict their effects on electron density. Step 3: Predict which molecule favors EAS.\"\n",
        "]\n",
        "\n",
        "visual_first_prompts = [\n",
        "    \"Observe visible features: are there -OH, -NH₂, or -NO₂ groups? Count and compare electron-donating versus electron-withdrawing groups for both molecules.\",\n",
        "    \"By examining only the visible substituents on the rings, conclude which molecule would favor electrophilic attack more easily.\"\n",
        "]\n",
        "\n",
        "explanation_first_prompts = [\n",
        "    \"Consider the net electronic effect (donating vs withdrawing) of all substituents. Based on that, decide which molecule is more reactive toward EAS.\",\n",
        "    \"Electron-withdrawing groups decrease EAS reactivity. Considering this, explain which molecule's structure favors substitution more.\"\n",
        "]\n",
        "\n",
        "all_prompts = baseline_prompt + stepwise_prompts + visual_first_prompts + explanation_first_prompts\n",
        "\n",
        "cot_types = (\n",
        "    [\"Baseline\"] +\n",
        "    [\"Stepwise\"] * len(stepwise_prompts) +\n",
        "    [\"Visual_first\"] * len(visual_first_prompts) +\n",
        "    [\"Explanation_first\"] * len(explanation_first_prompts)\n",
        ")\n",
        "\n",
        "# ----- 3. Define Image Pairs -----\n",
        "dataset_folder = \"/content\"\n",
        "image_pairs = [\n",
        "    (\"Aniline.png\", \"Nitrobenzene.png\"),\n",
        "    (\"Benzene.png\", \"Toluene.png\"),\n",
        "    (\"Benzaldehyde.png\", \"Benzoic_acid.png\")\n",
        "]\n",
        "\n",
        "# ----- 4. Output Setup -----\n",
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "csv_file = open(\"outputs/Task1_deepseek_finetune-res.csv\", \"w\", encoding=\"utf-8\", newline=\"\")\n",
        "writer = csv.DictWriter(csv_file, fieldnames=[\"image1\", \"image2\", \"prompt_type\", \"prompt_number\", \"prompt_text\", \"generated_text\"])\n",
        "writer.writeheader()\n",
        "\n",
        "# ----- 5. Inference -----\n",
        "for img1, img2 in image_pairs:\n",
        "    img_path1 = os.path.join(dataset_folder, img1)\n",
        "    img_path2 = os.path.join(dataset_folder, img2)\n",
        "    for idx, prompt_template in enumerate(all_prompts):\n",
        "        prompt_type = cot_types[idx]\n",
        "        conversation = [\n",
        "            {\n",
        "                \"role\": \"User\",\n",
        "                \"content\": prompt_template,\n",
        "                \"images\": [img_path1, img_path2]\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"Assistant\",\n",
        "                \"content\": \"\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        images = load_pil_images(conversation)\n",
        "        prepare_inputs = vl_chat_processor(\n",
        "            conversations=conversation,\n",
        "            images=images,\n",
        "            force_batchify=True\n",
        "        ).to(model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs_embeds = model.prepare_inputs_embeds(**prepare_inputs)\n",
        "            outputs = model.language_model.generate(\n",
        "                inputs_embeds=inputs_embeds,\n",
        "                attention_mask=prepare_inputs.attention_mask,\n",
        "                pad_token_id=tokenizer.eos_token_id,\n",
        "                bos_token_id=tokenizer.bos_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id,\n",
        "                max_new_tokens=512,\n",
        "                do_sample=False,\n",
        "                use_cache=True\n",
        "            )\n",
        "\n",
        "        answer = tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=True)\n",
        "        print(f\"--- Finished {prompt_type} #{idx+1} for {img1} and {img2}\")\n",
        "        writer.writerow({\n",
        "            \"image1\": img1,\n",
        "            \"image2\": img2,\n",
        "            \"prompt_type\": prompt_type,\n",
        "            \"prompt_number\": idx + 1,\n",
        "            \"prompt_text\": prompt_template,\n",
        "            \"generated_text\": answer.strip()\n",
        "        })\n",
        "\n",
        "csv_file.close()\n",
        "print(\"!!!! All pair inference completed and saved to outputs/Task1_deepseek_finetune-res.csv\")\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "oULS0khZrXrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!source /usr/local/bin/activate py38 && python task1-deepseek-finetune.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPe3lmmErXk0",
        "outputId": "7dcdb098-bcc8-4da5-fa90-0f9d6ca918c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/envs/py38/lib/python3.8/site-packages/transformers/models/auto/image_processing_auto.py:520: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
            "  warnings.warn(\n",
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "Loading checkpoint shards: 100% 3/3 [00:04<00:00,  1.35s/it]\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n",
            "Some kwargs in processor config are unused and will not have any effect: sft_format, num_image_tokens, add_special_token, ignore_id, image_tag, mask_prompt. \n",
            "--- Finished Baseline #1 for Aniline.png and Nitrobenzene.png\n",
            "--- Finished Stepwise #2 for Aniline.png and Nitrobenzene.png\n",
            "--- Finished Stepwise #3 for Aniline.png and Nitrobenzene.png\n",
            "--- Finished Visual_first #4 for Aniline.png and Nitrobenzene.png\n",
            "--- Finished Visual_first #5 for Aniline.png and Nitrobenzene.png\n",
            "--- Finished Explanation_first #6 for Aniline.png and Nitrobenzene.png\n",
            "--- Finished Explanation_first #7 for Aniline.png and Nitrobenzene.png\n",
            "--- Finished Baseline #1 for Benzene.png and Toluene.png\n",
            "--- Finished Stepwise #2 for Benzene.png and Toluene.png\n",
            "--- Finished Stepwise #3 for Benzene.png and Toluene.png\n",
            "--- Finished Visual_first #4 for Benzene.png and Toluene.png\n",
            "--- Finished Visual_first #5 for Benzene.png and Toluene.png\n",
            "--- Finished Explanation_first #6 for Benzene.png and Toluene.png\n",
            "--- Finished Explanation_first #7 for Benzene.png and Toluene.png\n",
            "--- Finished Baseline #1 for Benzaldehyde.png and Benzoic_acid.png\n",
            "--- Finished Stepwise #2 for Benzaldehyde.png and Benzoic_acid.png\n",
            "--- Finished Stepwise #3 for Benzaldehyde.png and Benzoic_acid.png\n",
            "--- Finished Visual_first #4 for Benzaldehyde.png and Benzoic_acid.png\n",
            "--- Finished Visual_first #5 for Benzaldehyde.png and Benzoic_acid.png\n",
            "--- Finished Explanation_first #6 for Benzaldehyde.png and Benzoic_acid.png\n",
            "--- Finished Explanation_first #7 for Benzaldehyde.png and Benzoic_acid.png\n",
            "!!!! All pair inference completed and saved to outputs/Task1_deepseek_finetune-res.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/outputs/Task1_deepseek_finetune-res.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "WqLDM8dYrXcF",
        "outputId": "aef14418-4e88-4977-f873-3b575e796060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ba9487f9-74df-4227-9737-292c512488d8\", \"Task1_deepseek_finetune-res.csv\", 21074)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}